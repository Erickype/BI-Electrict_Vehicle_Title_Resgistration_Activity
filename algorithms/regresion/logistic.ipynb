{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../datasetProcessing/datasets/final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    9634\n",
      "1    9634\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erick\\AppData\\Local\\Temp\\ipykernel_2068\\4151952122.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  extracted_classes['label'] = extracted_classes['label'].map(label_mapping)\n"
     ]
    }
   ],
   "source": [
    "unique_classes = data['label'].unique()\n",
    "\n",
    "# Randomly select two different classes\n",
    "random_classes = random.sample(list(unique_classes), 2)\n",
    "\n",
    "extracted_classes = data[data['label'].isin(random_classes)]\n",
    "\n",
    "label_mapping = {random_classes[0]: 1, random_classes[1]: 0}\n",
    "extracted_classes['label'] = extracted_classes['label'].map(label_mapping)\n",
    "\n",
    "data = extracted_classes\n",
    "print(data[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17341, 116) (17341,)\n",
      "(1927, 116) (1927,)\n"
     ]
    }
   ],
   "source": [
    "parts = 1\n",
    "# Split features and labels\n",
    "X = data.iloc[:int(data.shape[0]/parts), :-1]  # Features (all columns except the last one)\n",
    "y = data.iloc[:int(data.shape[0]/parts), -1]\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = map(np.array, train_test_split(X, y, test_size=0.1, random_state=42))\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_te.shape, y_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import log,dot,exp,shape\n",
    "\n",
    "def standardize(X_tr):\n",
    "    for i in range(shape(X_tr)[1]):\n",
    "        X_tr[:,i] = (X_tr[:,i] - np.mean(X_tr[:,i]))/np.std(X_tr[:,i])\n",
    "def F1_score(y,y_hat):\n",
    "    tp,tn,fp,fn = 0,0,0,0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1 and y_hat[i] == 1:\n",
    "            tp += 1\n",
    "        elif y[i] == 1 and y_hat[i] == 0:\n",
    "            fn += 1\n",
    "        elif y[i] == 0 and y_hat[i] == 1:\n",
    "            fp += 1\n",
    "        elif y[i] == 0 and y_hat[i] == 0:\n",
    "            tn += 1\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1_score = 2*precision*recall/(precision+recall)\n",
    "    return f1_score\n",
    "class LogisticRegression:\n",
    "    def sigmoid(self,z):\n",
    "        sig = 1/(1+exp(-z))\n",
    "        return sig\n",
    "    def initialize(self,X):\n",
    "        weights = np.zeros((shape(X)[1]+1,1))\n",
    "        X = np.c_[np.ones((shape(X)[0],1)),X]\n",
    "        return weights,X\n",
    "    def fit(self,X,y,alpha=0.001,iter=400):\n",
    "        weights,X = self.initialize(X)\n",
    "        def cost(theta):\n",
    "            z = dot(X,theta)\n",
    "            cost0 = y.T.dot(log(self.sigmoid(z)))\n",
    "            cost1 = (1-y).T.dot(log(1-self.sigmoid(z)))\n",
    "            cost = -((cost1 + cost0))/len(y)\n",
    "            return cost\n",
    "        cost_list = np.zeros(iter,)\n",
    "        for i in range(iter):\n",
    "            weights = weights - alpha*dot(X.T,self.sigmoid(dot(X,weights))-np.reshape(y,(len(y),1)))\n",
    "            cost_list[i] = cost(weights)\n",
    "        self.weights = weights\n",
    "        return cost_list\n",
    "    def predict(self,X):\n",
    "        z = dot(self.initialize(X)[1],self.weights)\n",
    "        lis = []\n",
    "        for i in self.sigmoid(z):\n",
    "            if i>0.5:\n",
    "                lis.append(1)\n",
    "            else:\n",
    "                lis.append(0)\n",
    "        return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erick\\AppData\\Local\\Temp\\ipykernel_2068\\117323648.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  cost_list[i] = cost(weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "obj1 = LogisticRegression()\n",
    "model= obj1.fit(X_tr,y_tr)\n",
    "y_pred = obj1.predict(X_te)\n",
    "y_train = obj1.predict(X_tr)\n",
    "#Let's see the f1-score for training and testing data\n",
    "f1_score_tr = F1_score(y_tr,y_train)\n",
    "f1_score_te = F1_score(y_te,y_pred)\n",
    "print(f1_score_tr)\n",
    "print(f1_score_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "model = LogisticRegression().fit(X_tr,y_tr)\n",
    "y_pred = model.predict(X_te)\n",
    "print(f1_score(y_te,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
